"use strict";(self.webpackChunkportfolio=self.webpackChunkportfolio||[]).push([[593],{593:(e,t,i)=>{i.r(t),i.d(t,{default:()=>l});var a=i(791),o=i(184);const s=function(e){let{title:t,tags:i,technologies:a,github:s}=e;return(0,o.jsxs)("div",{className:"caption",children:[(0,o.jsx)("h3",{children:t}),Array.isArray(i)&&i.map(((e,t)=>(0,o.jsx)("div",{className:"skill tag",children:e},t))),Array.isArray(a)&&a.map(((e,t)=>(0,o.jsx)("div",{className:"skill technology",children:e},t))),s&&""!==s.trim()&&(0,o.jsx)("div",{className:"skill github",children:(0,o.jsx)("a",{href:s,target:"_blank",rel:"noopener noreferrer",children:"GitHub"})})]})};const n=function(e){let{content:t,images:i,videos:a}=e;const s=i.slice(1);return(0,o.jsxs)("div",{className:"details",children:[(0,o.jsx)("div",{className:"content",children:t}),(0,o.jsx)("div",{className:"images",children:s.map((e=>(0,o.jsx)("img",{src:e,alt:"",loading:"lazy"},e)))}),(0,o.jsx)("div",{className:"videos",children:a.map(((e,t)=>(0,o.jsx)("iframe",{title:"Video ".concat(t+1),autoPlay:!0,src:e,style:{position:"relative",top:0,left:0,width:"100%",height:"100%",aspectRatio:"16 / 9"},loading:"lazy"},t)))})]})};var r=i(382);i(699);const l=(0,a.memo)((function(){const e=[{title:"Real-time Interactive 3D Volume Animation of Cosmology Simulations",content:"This is my final chapter of my PhD thesis. Most cosmology simulation visualization software only allows for viewing a single snapshot at a time. To overcome this, I engineered an animation playback system for viewing 3D volumes of simulations by loading in a sequence of volumes into memory. Color scales (transfer functions) can be adjusted in real time and apply to each frame in the animation.",images:["images/halo-zoom-in-temperature.webp"],videos:["https://drive.google.com/file/d/16uleUvM8iTQegYxGzWfOzbMGwbn7476r/preview","https://drive.google.com/file/d/10t96IqzHLXRkbdt2WxHcTG5dhx2UNVDN/preview","https://drive.google.com/file/d/1zcds0OBStnpAgVE44nnNq6tWVEp36AFy/preview","https://drive.google.com/file/d/1S7BgtMn6L_1hjvnc6gSpLr9dCXoK7Fg6/preview","https://drive.google.com/file/d/12aYpxd2pa9zLJOMfhYZ8XmM-uHkSyntK/preview"],demoLink:"http://demo-link-project1.com",githubLink:"http://github-link-project1.com",tags:["data-vis","3d-graphics","interactive","animation"],technologies:["HTML","CSS","Javascript","THREE","GLSL","D3","Python","Figma"]},{title:"CosmoVis: An Interactive Visual Analysis Tool for Exploring Hydrodynamic Cosmological Simulations",content:"CosmoVis is an open-source web-based astrophysics visualization tool that facilitates the interactive analysis of large-scale hydrodynamic cosmological simulation datasets. CosmoVis enables astrophysicists as well as citizen scientists to share and explore these datasets, which are often comprised of complex, unwieldy data structures greater that 1 TB in size. Our tool visualizes a range of salient gas, dark matter, and stellar attributes extracted from the source simulations, and enables further analysis of the data using observational analogues, specifically absorption line spectroscopy. CosmoVis introduces novel analysis functionality through the use of virtual skewers that define a sightline through the volume to quickly obtain detailed diagnostics about the gaseous medium along the path of the skewer, including synthetic spectra that can be used to make direct comparisons with observational datasets.",images:["/images/TNG100_z2.3_teaser_highres_adjusted1.webp","images/sheet_use_case_1.webp","images/512EAGLE25Mpc.webp","images/512TNG100Mpc_z2_3_slice10.webp"],videos:["https://drive.google.com/file/d/1a_X2AfBIoc_1OXIR4yRYXoSWPJzI35O8/preview","https://player.vimeo.com/video/535010028?portrait=0"],demoLink:"",githubLink:"https://github.com/CreativeCodingLab/CosmoVis",tags:["data-vis","3d-graphics","interactive"],technologies:["HTML","CSS","Javascript","THREE","GLSL","D3","Python","Flask","SocketIO","Figma","AWS (EC2 & S3)","Docker","Kubernetes"]},{title:"Fraction8: Interactive 3D Spacecraft Simulation Visualization",content:"Fraction8 was a visualization solution for hydrodynamic fluid simulations of spacecraft concept designs at JPL. In collaboration with researchers, we developed an interactive small multiple 3D visualization that could simulataneously display multiple physical parameters. One key task enabled with this tool was displaying relative ion fractions inside and outside of the spacecraft, which would measure the composition of the upper atmosphere of Venus. Using a novel 2D/3D graph implementation, relative quantitative differences are visually encoded in both color as well as height to get a more intuitive sense of different regions.",images:["images/hypervelocity/hyp.webm","images/hypervelocity/image (3).webp","images/hypervelocity/image (5).webp","images/hypervelocity/image (10).webp"],videos:[],demoLink:"",githubLink:"",tags:["data-vis","3d-graphics","interactive"],technologies:["HTML","CSS","Javascript","THREE","GLSL","D3","Python"]},{title:"RuleVis: Browser-based 2D  tool for visually coding protein interactions",content:"RuleVis, a web-based application for defining and editing correct-by-construction executable rules that model biochemical functionality, and which can be used to simulate the behavior of protein-protein interaction networks and other complex systems. Our application bridges the graph rewriting and systems biology research communities by providing an external visual representation of salient patterns that experts can use to determine the appropriate level of detail in a particular modeling context. This project is a collaboration between the UCSC Creative Coding Lab and the Walter Fontana Group at Harvard Medical School. Our short paper has been accepted to IEEE VIS 2019. The tool uses the same syntax from the Kappa Language, a rule-based language for modeling interacting networks.",images:["images/teaser_rulevis.webp"],videos:["https://player.vimeo.com/video/535101002?autoplay=1&loop=1&portrait=0","https://player.vimeo.com/video/374691687?portrait=0"],demoLink:"",githubLink:"https://github.com/CreativeCodingLab/RuleVis",tags:["data-vis","2d-graphics","interactive"],technologies:["HTML","CSS","Javascript","D3"]},{title:"Word \u201cStream\u201d Visualization",content:"In the summer of 2022 I traveled to Bogota, Colombia to intern in Lab En Flujo (in flow) and contributed to this words stream visualization using HTML, CSS, JS, THREE.js and custom shader code. The goal of this visualization is to see the frequency of a set of keywords from Twitter how it changes over time by encoding the frequency as the height of the word. In a traditional word map, a piece of text is analyzed and each word is visualzied once, where the size is determined by the frequency of that word. However in this case, we want to see the use of words changes over time and visualize them in a visual stream of words.",images:["images/word_stream_zoom.webp","images/word_stream.webp"],videos:[],demoLink:"",githubLink:"https://github.com/davramov/colev-tendencias",tags:["data-vis","3d-graphics"],technologies:["HTML","CSS","Javascript","THREE","GLSL","React"]},{title:"Colombian COVID Prediction Visualization (With Historical Data)",content:"I worked on this project in collaboration with Lab En Flujo (in flow) when I was an intern in Bogota, Colombia. The goal of this tool was to compare recorded Covid-19 case and death rates with the predictions created by statisticians. Users can select between seeing case and death rates, daily and weekly aggregations, and filter future predictions based on the selected date, along with confidence intervals. A tooltip appears when hovering over chart, and users can zoom in to a smaller time period using the slider at the bottom. This interactive data visualization was created using D3.js.",images:["images/pronostico.webp"],videos:["https://drive.google.com/file/d/1ZYb-bt9ugEvJlIZEgkL1gDflFZGmhc1T/preview"],demoLink:"https://colev.enflujo.com/pronostico-covid19/",githubLink:"https://github.com/davramov/colev-pronostico-covid19",tags:["data-vis","2d-graphics","interactive"],technologies:["HTML","CSS","Javascript","D3","React"]},{title:"IGM\u2010Vis: Analyzing Intergalactic and Circumgalactic Medium Absorption Using Quasar Sightlines in a Cosmic Web Context",content:"The Intergalactic Media Visualization, or IGM-Vis, is a novel visualization and data analysis platform for investigating galaxies and the gas that surrounds them in context with their larger scale environment, the Cosmic Web. Environment is an important factor in the evolution of galaxies from actively forming stars to a quiescent state with little, if any, discernible star formation activity. The gaseous halos of galaxies (the circumgalactic medium, or CGM) play a critical role in their evolution, because the gas necessary to fuel star formation and any gas expelled from widely observed galactic winds must encounter this interface region between galaxies and the intergalactic medium (IGM).",images:["images/igmvis/IGM-Vis_overview.webp"],videos:["https://www.youtube-nocookie.com/embed/3ZVaExEVZOk"],demoLink:"https://creativecodinglab.github.io/Intergalactic/intergalactic.html",githubLink:"https://github.com/CreativeCodingLab/Intergalactic",tags:["data-vis","2d-graphics","3d-graphics"],technologies:["HTML","CSS","Javascript","THREE","GLSL"]},{title:"Raccoon Runner",content:"Raccoon Runner is an infinite runner game I have been working on in Unreal Engine. In the game, you play as Ralphie the Raccoon who runs around the alleys picking up trash (and treasures), and selling the items to a friendly sewer rat Ronnie in exchange for spare change.",images:["images/ronnie_the_rat.webp","images/raccoon.png"],videos:["https://player.vimeo.com/video/892749792"],demoLink:"",githubLink:"",tags:["3d-graphics","interactive"],technologies:["Blender","Unreal Engine","C++"]},{title:"DenseVOS - AI Driven Visual Art Installation",content:"DenseVOS is an installation that introduces a salient region detection, convolutional architecture (DenseCap) within an existing internationally exhibited artwork &ldquo;Voice of Sisyphus&rdquo; (VOS) whose major feature has been to filter selected regions of a single photographic image in varying ways to produce a 4-channel surround sound experience. This revised version uses a live camera feed to provide updated images that are then autonomously parsed by DenseCap to select the regions of interest to be filtered and audified. As the translation of image regions to audio is based on a FFT analysis of the selected regions&rsquo; pixels, the intent of the project is to explore to what degree a convolution-network based software trained on 94,000 images and 4,100,1000 region grounded captions, can deliver aesthetically interesting results given that the training has been function driven for object detection and labeling.",images:["images/vos_process1.webm"],videos:[],demoLink:"",githubLink:"",tags:["2d-graphics","AI/ML"],technologies:["Processing","C++","openFrameworks","DenseCap","Python","PyTorch"]},{title:"\u201dThrow Me Away\u201d Video Installation",content:"\u201cThrow Me Away\u201c is a 2-minute looping video installation that was presented at UCSC's Digital Art and New Media open studio. I combined found and original recorded footage, datamoshing techniques, and an original audio accompanyment that features a corrupt virtual assistant instructing the viewer to \u201cthrow me away.\u201c",images:["images/danm-poster_crop.webp"],videos:["https://player.vimeo.com/video/309172057?byline=0&portrait=0"],demoLink:"",githubLink:"",tags:["2d-graphics"],technologies:["ffmpeg"]},{title:"Unity Demo Scene: Chaotic Kitchen with Popcorn Particles",content:"I created this scene in Unity to demonstrate physics-based particle systems with collisions and meshes for my Game Technologies class at UC Santa Cruz. In this example, I placed a particle system emitter inside of the cooking pot the generates a popcorn kernal mesh with an initial velocity, some weight and collisions enabled. At a certain point, the net force of the collective popcorn kernals is enough to overcome the weight of the lid, and popcorn kernals fly around the kitchen.",images:["images/popcorn.webp"],videos:[],demoLink:"",githubLink:"",tags:["3d-graphics"],technologies:["Unity","C#"]},{title:"Unity Demo Scene: Alien UFO Tractor Beam with Flying Controls and Collision",content:"For this project, I created a flying scene in Unity to show my Game Technologies students a few techniques. In this scene a camera follows a player component (in this case an alien in a UFO). A 2D texture particle emitter is used to animate a glowing green tractor beam underneath the spaceship. Additionally, the UFO can be controlled using the keyboard to rotate left, right, move forwards and backwards, as well as rotate clockwise and counterclockwise. A laser blaster can be emitted, which sends sphere particles out from the front of the UFO. Additionally, the planets can be collided with and follow orbital mechanics.",images:["images/UFO.webp"],videos:[],demoLink:"",githubLink:"",tags:["3d-graphics"],technologies:["Unity","C#"]},{title:"Unity Demo Scene: Audio Driven Reactivity - Coconut Emitter",content:"This is a sound recognition Unity demo I made for students in my Game Graphics lab sections. Coconuts fall from the tree at the response of the bongo drums in the audio loop that I composed and recorded with my OP-1 sampler/synthesizer. In Unity, the students had to import the demo assets (textures, shaders, objects), and modify an audio script to listen for the bongo sound. Using the sound as a trigger, they had to modify a couple of other scripts: a particle emmitter for the coconuts, and a tree shake in another script.",images:["images/coconut_island.webp"],videos:["https://player.vimeo.com/video/533805564?loop=1&portrait=0"],demoLink:"",githubLink:"",tags:["3d-graphics"],technologies:["Unity","C#"]},{title:"Procedural Crystal Generator",content:"I created a crystal object generator in Blender using geometry nodes, where smaller versions of the parent object are scattered about in a randomized, crystalline pattern. I originally created this to be used for the Crystal Note Grove installation at the Santa Cruz Museum of Art and History (as seen in this image with a creature sculpture I 3D scanned). To get the object to work on the Home page of my portfolio, I had to significantly reduce the number of vertices, export to a DRACO compressed gltf file format, and use a MeshPhysicalMaterial in Three.js to configure the color and reflection properties.",images:["images/crystal_bug_cc1.webp"],videos:[],demoLink:"",githubLink:"",tags:["3d-graphics"],technologies:["Blender","THREE","React","HTML","CSS","Javascript"]},{title:"Weather Balloon Altitude Control System",content:"One summer during undergrad I had the opportunity to work in the Far Horizons Lab at the Adler Planetarium, where I designed, built and tested an altitude control system for their weather balloon flights. Prior to this device, the team would simply overfill their helium balloons such that they would rise to the edge of the atmosphere, the balloon would grow to the size of a small house, and then pop -- dropping the payload back down to Earth, where the team would track it using GPS transmitters. In order to sustain longer flights, I developed a helium venting system using a rubber stopper, linear actuator, pressure sensor, and an Arduino Uno. The system would start in a locked position, where the rubber stopper would seal a connection to a PVC tube attached to the balloon to prevent helium initially leaking out. As the balloon ascends, the altitude control system moves to an intermediate position where helium can vent out. Once the desired altitude is reached, the venting system goes back into the sealed position. This way, the balloon can reach neutral bouyancy in a part of the atmosphere with minimal turbulence. Once the flight is complete, the system moves the stopper to a final position, whereby the PVC insert has enough space to detatch from the balloon.",images:["https://66.media.tumblr.com/86ed69670cb5bc941a84e93f6209b29b/tumblr_oeag76u91I1vyt7too1_1280.jpg","images/helium-vent-animation.gif","https://64.media.tumblr.com/6b00d7d153d83c201099f0d93db990b5/tumblr_oeaitaG1iv1vyt7too1_1280.jpg"],videos:["https://player.vimeo.com/video/184948745?byline=0&portrait=0"],demoLink:"",githubLink:"",tags:["electronics"],technologies:["MatLab","Arduino","Fusion360","3D Printing"]},{title:"Crystal Note Grove",content:"I contributed lighting, programming, and 3D scanning skills as a technical artist with the Liminal Space Art Collective in Santa Cruz, CA. This project was an art installation in the lobby of the Santa Cruz Museum of Art and History (MAH) for their Frequency Light Festival. This was an interactive exhibit with a large tree as the centerpiece and crystal creatures in their mystical environment. I oversaw the lighting budget, designed and implemented an audio-synchronized fiber optic lighting system strung throughout the ecosystem to simulate glowing tufts of moss, as well as 3D scanning of the creatures, and various carpentry tasks.",images:["images/creature_preview.webp","crystal_bug_cc.png"],videos:[],demoLink:"",githubLink:"",tags:["electronics"],technologies:["PixelBlaze","Blender","3D Scanning","3D Printing"]},{title:"VR Location History",content:"I created this VR app for my Immersive Analytics class. The goal of this project was to take some personal data and visualize it in some way. I chose my location history as tracked by Google Maps. I was able to create a 2D heatmap using the MapBox API. I extended this 2D heatmap into VR by placing virtual pins on a realistic elevation view using Unity. The user could use the controllers to navigate the digital world and view where I had been.",images:["images/VR_location1.webp"],videos:[],demoLink:"",githubLink:"https://github.com/davramov/immersive-analytics/tree/master/VR%20Location%20History",tags:["data-vis","3d-graphics"],technologies:["Unity","C#","VR","MapBox"]}],t=e.slice(0,e.length),[i,l]=(0,a.useState)(null),[c,h]=(0,a.useState)(Array(t.length).fill(!1)),[d,m]=(0,a.useState)(0),[g,u]=(0,a.useState)(!0),[p,v]=(0,a.useState)([]),b=[...new Set(e.flatMap((e=>e.tags)))],y=p.length>0?t.filter((e=>e.tags.some((e=>p.includes(e))))):t;return(0,o.jsx)("section",{id:"projects",children:(0,o.jsx)("div",{className:"main-container projects-container",children:(0,o.jsxs)("div",{className:" projects-panel",children:[(0,o.jsx)(r.Z,{text:"Projects",iconName:"projects"}),(0,o.jsxs)("button",{onClick:()=>{u(!g),v([])},children:["Switch to ",g?"Column":"Grid"," Mode"]}),(0,o.jsxs)("div",{className:"filter-buttons",children:["Filter by type:",b.map((e=>(0,o.jsx)("button",{onClick:()=>(e=>{const t=p.includes(e)?p.filter((t=>t!==e)):[...p,e];v(t)})(e),className:p.includes(e)?"active":"",children:e},e))),(0,o.jsx)("button",{onClick:()=>{v([])},children:"Clear Filters"})]}),(0,o.jsx)("div",{className:"main-projects-container ".concat(g?"grid-mode":"column-mode"),children:y.map(((e,t)=>{const a=i===t,r={zIndex:a?2e3:1,top:a?"15%":"auto",left:a?"15%":"auto",right:a?"15%":"auto",bottom:a?"15%":"auto",width:"100%",height:"auto"};return(0,o.jsxs)("div",{className:"project project-".concat(t," ").concat(a?"expanded":""),style:r,onClick:()=>(e=>{if(null===i&&m(window.scrollY),l(i===e?null:e),i===e)window.scrollTo({top:d,behavior:"smooth"});else{const t=document.getElementById("project-".concat(e));t&&t.scrollIntoView({behavior:"smooth",block:"start"})}})(t),children:[(g=e.images[0],g&&g.toLowerCase().endsWith(".webm")?(0,o.jsxs)("video",{className:"project-video",autoPlay:!0,loop:!0,muted:!0,loading:"lazy",playsInline:!0,style:{width:"100%",height:"100%"},children:[(0,o.jsx)("source",{src:e.images[0],type:"video/webm"}),"Your browser does not support the video tag."]}):(0,o.jsx)("img",{className:"project-image",src:e.images[0]||"",alt:e.title,style:{width:"100%",height:"auto"},loading:c[t]?"eager":"lazy",onLoad:()=>(e=>{const t=[...c];t[e]=!0,h(t)})(t)})),(0,o.jsx)(s,{title:e.title,tags:e.tags,technologies:e.technologies,github:e.githubLink}),a&&(0,o.jsx)(n,{content:e.content,images:e.images,videos:e.videos})]},t);var g}))})]})})})}))},382:(e,t,i)=>{i.d(t,{Z:()=>o});i(791);var a=i(184);const o=function(e){let{text:t,iconName:i}=e;return(0,a.jsx)("div",{className:"section-header",children:(0,a.jsxs)("h2",{children:[(0,a.jsx)("img",{src:"/icons/".concat(i,".svg"),alt:"".concat(i," icon"),className:"section-icon"}),t]})})}},699:()=>{}}]);
//# sourceMappingURL=593.79a49980.chunk.js.map